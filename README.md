#  Multiplicaci贸n de Matrices con Procesos Paralelos en C y Go

**Universidad de Antioquia**  
*Curso: Sistemas Operativos*  
*Pr谩ctica #2 - Multiplicaci贸n de matrices con procesos*

##  Integrantes

- [x] [Maritza Tabarez C谩rdenas](https://github.com/MaritzaTC)
- [x] [Juan David Vasquez Ospina](https://github.com/JuanVasquezO)

##  Objetivos

<details>
<summary>Ver objetivos del proyecto</summary>

- Comprender la creaci贸n de procesos usando `fork()`.
- Implementar c贸mputo paralelo dividiendo la carga de trabajo entre m煤ltiples procesos (en C) o gorutinas (en Go) usando APIs del sistema operativo.
- Aprender y aplicar mecanismos de comunicaci贸n entre procesos (IPC), como pipes o memoria compartida (en C), y canales o estructuras para compartir memoria (en Go).
- Analizar y comparar el rendimiento entre las implementaciones secuenciales y paralelas de la multiplicaci贸n de matrices.

</details>

---

##  Descripci贸n del problema

<details>
<summary>Ver descripci贸n completa</summary>

Desarrollar un programa en C que multiplique dos matrices grandes:

- Matriz A (NM)  
- Matriz B (MP)  
- Resultado: Matriz C (NP)

</details>

##  Implementaciones

<details>
<summary>Para C</summary>

Se debe implementar:

-  Versi贸n secuencial (`sequential.c`)  
-  Versi贸n paralela con procesos (`parallel.c`) usando memoria compartida
-  Version secuencial y paralela (`sequientialAndParallel.c`)

</details>

## 锔 Compilaci贸n y ejecuci贸n

<details>
<summary>Instrucciones de compilaci贸n</summary>

Usar `gcc` para compilar:

```bash
gcc sequential.c -o sequential
gcc parallel.c -o parallel
gcc sequientialAndParallel.c -o parallel_matrix_multiply
```

</details>

<details>
<summary>Instrucciones de ejecuci贸n</summary>

```bash
./sequential
./parallel
```

Al ejecutar, el programa pedir谩 las dimensiones de las matrices (N, M, P) y leer谩 los datos desde los archivos A.txt y B.txt. El resultado se escribir谩 en C.txt.

</details>

##  Entrada y Salida

<details>
<summary>Ver detalles</summary>

- **Entrada**: Archivos A.txt, A_small.txt, A_big y B.txt, B_small.txt, B_big con los valores de las matrices.
- **Salida**: Archivo C.txt con la matriz resultado.

</details>

---

#  Informe T茅cnico

##  Elecci贸n del mecanismo IPC

<details>
<summary>Ver justificaci贸n t茅cnica</summary>

Para la implementaci贸n paralela, se utiliz贸 memoria compartida (Shared Memory) mediante las funciones `shmget()` y `shmat()` de la API de System V.

Esta elecci贸n se basa en:

- **Velocidad**: La memoria compartida permite el acceso directo a la regi贸n com煤n de memoria, lo que evita copias innecesarias de datos.
- **Simplicidad en agregaci贸n**: Los procesos hijos escriben directamente en la matriz C, eliminando la necesidad de combinar resultados tras el c谩lculo.
- **Escalabilidad**: Es m谩s eficiente que otros mecanismos como pipes para grandes vol煤menes de datos.

</details>

##  An谩lisis de Rendimiento

<details>
<summary>Ver capturas de pantalla de resultados</summary>

![Resultados 1](Screenshot%202025-05-14%20183333.png)
![Resultados 2](Screenshot%202025-05-14%20190748.png)
![Resultados 3](Screenshot%202025-05-14%20195626.png)

</details>

<details>
<summary>Ver tabla de tiempos y speedup</summary>

|   N |   M |   P | N潞 Procesos | Tiempo Secuencial (s) | Tiempo Paralelo (s) | Speedup |
|-----|-----|-----|-------------|----------------------|---------------------|---------|
| 12  | 15  | 10  | 1           | 0.0001               | 0.0019              | 0.05    |
| 12  | 15  | 10  | 2           | 0.0001               | 0.0027              | 0.03    |
| 12  | 15  | 10  | 3           | 0.0001               | 0.0037              | 0.02    |
| 12  | 15  | 10  | 4           | 0.0001               | 0.0045              | 0.02    |
| 2   | 3   | 2   | 1           | 0.0001               | 0.0015              | 0.05    |
| 2   | 3   | 2   | 2           | 0.0001               | 0.0028              | 0.02    |
| 2   | 3   | 2   | 3           | 0.0001               | 0.0036              | 0.02    |
| 2   | 3   | 2   | 4           | 0.0001               | 0.0044              | 0.02    |
| 400 | 360 | 400 | 1           | 1.0425               | 0.0386              | 26.99   |
| 400 | 360 | 400 | 2           | 0.8743               | 0.0212              | 41.26   |
| 400 | 360 | 400 | 3           | 0.9131               | 0.0347              | 26.34   |
| 400 | 360 | 400 | 4           | 0.9994               | 0.0491              | 20.33   |

</details>

<details>
<summary>Ver gr谩fico de Speedup vs N煤mero de Procesos</summary>

![Gr谩fico de Speedup vs N煤mero de Procesos](Figure_1.png)

</details>

###  Interpretaci贸n de resultados

<details>
<summary>Para matrices peque帽as (2x3 x 3x2 y 12x15 x 15x10)</summary>

- El speedup es muy bajo, incluso menor que 1 en algunos casos, lo que indica que la versi贸n paralela no es eficiente para estos tama帽os peque帽os.
- De hecho, el tiempo paralelo es incluso mayor que el secuencial, reflejado en speedups menores a 1 (0.05, 0.02, etc.).
- Esto se debe a que la sobrecarga de crear y gestionar procesos, sincronizar y dividir el trabajo supera cualquier beneficio que se obtenga al paralelizar la multiplicaci贸n de matrices tan peque帽as.
- Adem谩s, aumentar el n煤mero de procesos no mejora significativamente el rendimiento; en algunos casos, lo empeora.

</details>

<details>
<summary>Para matrices grandes (400x360 x 360x400)</summary>

- El speedup es mucho mayor, llegando a valores superiores a 20 o 40 en algunos casos, lo que indica que la paralelizaci贸n s铆 da un gran beneficio.
- Esto es esperado porque con matrices grandes la carga de trabajo es mayor, por lo que dividir la tarea entre procesos reduce mucho el tiempo total.
- Sin embargo, el speedup no crece de forma perfectamente lineal con el n煤mero de procesos: hay un m谩ximo (41.26 con 2 procesos) y luego baja.
- Esta ca铆da puede ser causada por la sobrecarga de comunicaci贸n y sincronizaci贸n entre procesos cuando se usan m谩s de dos procesos, o limitaciones de hardware (como n煤mero de n煤cleos f铆sicos disponibles).
- A煤n as铆, la paralelizaci贸n es claramente beneficiosa para cargas de trabajo grandes.

</details>

##  Implementaci贸n en Go

<details>
<summary>Descripci贸n general</summary>

El programa en Go implementa la multiplicaci贸n de matrices tanto de forma secuencial como paralela, utilizando goroutines y pipes para la concurrencia.

</details>

<details>
<summary>Estructura del Programa</summary>

#### Funciones para manejo de archivos:
- `readMatrixFromFile`: Lee los datos de la matriz desde un archivo de texto.
- `writeMatrixToFile`: Escribe la matriz resultante en un archivo de texto.

#### Multiplicaci贸n de matrices:
- `workerMultiply`: Funci贸n que realiza la multiplicaci贸n parcial de matrices en una goroutine y env铆a los resultados a trav茅s de un pipe.
- `multiplyMatricesParallelWithPipes`: Funci贸n que crea las goroutines (workers), los pipes, distribuye el trabajo entre los workers y recoge los resultados de los pipes para construir la matriz final.
- `multiplyMatricesSequential`: Funci贸n que realiza la multiplicaci贸n de matrices de forma secuencial.

#### Funci贸n main:
- Procesa los argumentos de la l铆nea de comandos: nombres de los archivos de entrada para las matrices A y B, y el n煤mero de workers (goroutines).
- Lee las matrices A y B desde los archivos.
- Realiza la multiplicaci贸n de matrices de forma secuencial y paralela.
- Imprime los tiempos de ejecuci贸n de ambas versiones y el speedup obtenido con la versi贸n paralela.
- Escribe la matriz resultado en un archivo.

</details>

<details>
<summary>Mecanismo IPC en Go</summary>

La implementaci贸n paralela en Go utiliza pipes para la comunicaci贸n entre las goroutines (workers). Cada worker calcula una porci贸n de la matriz resultado y env铆a los resultados (铆ndices de la celda y valor calculado) a trav茅s de un pipe. La funci贸n principal lee los resultados de los pipes y construye la matriz resultado final.

#### Paralelismo con Goroutines
Go utiliza goroutines para lograr la ejecuci贸n paralela. La carga de trabajo se divide entre las goroutines, permitiendo que m煤ltiples porciones de la matriz se calculen simult谩neamente.

</details>

##  Comparaci贸n entre implementaciones

<details>
<summary>C vs Go</summary>

Aunque ambas implementaciones buscan paralelizar la multiplicaci贸n de matrices, utilizan diferentes enfoques y mecanismos de IPC:

#### C:
- Utiliza procesos separados y memoria compartida para la comunicaci贸n.
- Los procesos hijos escriben los resultados directamente en una regi贸n de memoria compartida.

#### Go:
- Utiliza goroutines (que son m谩s ligeras que los procesos) y pipes para la comunicaci贸n.
- Los workers env铆an los resultados a trav茅s de pipes, y la goroutine principal los recoge.

Ambos enfoques tienen como objetivo mejorar el rendimiento al dividir la carga de trabajo, pero difieren en la forma en que se gestionan los procesos/goroutines y c贸mo se comunican.

</details>

##  Referencias

<details>
<summary>Ver referencias</summary>

- OSTEP: Processes API Chapter.
- Linux man pages: `fork()`, `shmget()`, `pipe()`

</details>
